{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQ+EIscohrbdbi6ZjDxFfD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Intro to Pyspark"],"metadata":{"id":"fJ-bP7KiIv90"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"kc52cqjRMj2J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695417627066,"user_tz":240,"elapsed":48876,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"ff0b1bd0-ef60-425d-9ad8-f9c42b20397a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=7f03a45d34040b0dca2bcfefcdc158da5123557869b08fd7ba056d1be999bc9e\n","  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.1\n"]}],"source":["# https://spark.apache.org/\n","!pip install pyspark\n"]},{"cell_type":"code","source":["from pyspark import SparkContext\n","\n","# Create a SparkContext\n","sc = SparkContext(\"local\", \"My Spark App\")"],"metadata":{"id":"CBBSXw809P8f","executionInfo":{"status":"ok","timestamp":1695418206154,"user_tz":240,"elapsed":10507,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Verify SparkContext\n","print(sc)\n","\n","# Print Spark version\n","print(sc.version)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKEgeePT9aRL","executionInfo":{"status":"ok","timestamp":1695269892036,"user_tz":240,"elapsed":143,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"c98633d1-eecf-40e1-ace3-35180aeb3ae7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<SparkContext master=local appName=My Spark App>\n","3.4.1\n"]}]},{"cell_type":"code","source":["# Import SparkSession from pyspark.sql\n","from pyspark.sql import SparkSession\n","\n","# Create my_spark\n","spark = SparkSession.builder.getOrCreate()\n","\n","# Print my_spark\n","print(spark)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rlr7GPI99ivt","executionInfo":{"status":"ok","timestamp":1695418253190,"user_tz":240,"elapsed":340,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"16ed3404-aea6-410a-ffb1-f7b7b3166f47"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<pyspark.sql.session.SparkSession object at 0x7d9dee46b160>\n"]}]},{"cell_type":"code","source":["# Print the tables in the catalog\n","print(spark.catalog.listTables())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6NMeTVug9ny5","executionInfo":{"status":"ok","timestamp":1695418262655,"user_tz":240,"elapsed":7987,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"3084bb12-3eaa-4363-917b-fcfc1bcaf145"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from pyspark.sql import SparkSession\n","\n","flights = spark.read.csv('/content/airport.csv', header=True, inferSchema=True)\n","\n","flights.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKakhzUG-TWI","executionInfo":{"status":"ok","timestamp":1695418267685,"user_tz":240,"elapsed":5034,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"8d0911b2-9d4e-434a-b8e7-f55890b64a46"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n","|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n","+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n","|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n","|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n","|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n","|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n","|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n","|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX| DEN|     121|     991|  10|    37|\n","|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX| OAK|      90|     543|   8|    47|\n","|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA| SFO|      98|     679|  16|    55|\n","|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|\n","|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|\n","|2014|   11|  8|    1653|       -2|    1924|       -1|     AS| N323AS|   448|   SEA| LAX|     130|     954|  16|    53|\n","|2014|    8|  3|    1120|        0|    1415|        2|     AS| N305AS|   656|   SEA| PHX|     154|    1107|  11|    20|\n","|2014|   10| 30|     811|       21|    1038|       29|     AS| N433AS|   608|   SEA| LAS|     127|     867|   8|    11|\n","|2014|   11| 12|    2346|       -4|     217|      -28|     AS| N765AS|   121|   SEA| ANC|     183|    1448|  23|    46|\n","|2014|   10| 31|    1314|       89|    1544|      111|     AS| N713AS|   306|   SEA| SFO|     129|     679|  13|    14|\n","|2014|    1| 29|    2009|        3|    2159|        9|     UA| N27205|  1458|   PDX| SFO|      90|     550|  20|     9|\n","|2014|   12| 17|    2015|       50|    2150|       41|     AS| N626AS|   368|   SEA| SMF|      76|     605|  20|    15|\n","|2014|    8| 11|    1017|       -3|    1613|       -7|     WN| N8634A|   827|   SEA| MDW|     216|    1733|  10|    17|\n","|2014|    1| 13|    2156|       -9|     607|      -15|     AS| N597AS|    24|   SEA| BOS|     290|    2496|  21|    56|\n","|2014|    6|  5|    1733|      -12|    1945|      -10|     OO| N215AG|  3488|   PDX| BUR|     111|     817|  17|    33|\n","+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["flights.createOrReplaceTempView(\"flights_temp_table\")\n","\n","query = 'FROM flights_temp_table SELECT * LIMIT 10'\n","\n","# Get the first 10 rows of flights\n","flights10 = spark.sql(query)\n","\n","# Show the results\n","flights10.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JVb8Mr0TBHoN","executionInfo":{"status":"ok","timestamp":1695271297543,"user_tz":240,"elapsed":678,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"6a625e4b-7a19-407a-d5bc-8d763ff7db22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n","|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n","+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n","|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n","|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n","|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n","|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n","|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n","|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX| DEN|     121|     991|  10|    37|\n","|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX| OAK|      90|     543|   8|    47|\n","|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA| SFO|      98|     679|  16|    55|\n","|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|\n","|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|\n","+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n","\n"]}]},{"cell_type":"code","source":["query = \"SELECT origin, dest, COUNT(*) as N FROM flights_temp_table GROUP BY origin, dest\"\n","\n","# Run the query\n","flight_counts = spark.sql(query)\n","\n","# Convert the results to a pandas DataFrame\n","pd_counts = flight_counts.toPandas()\n","\n","# Print the head of pd_counts\n","print(pd_counts.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHGH7zrhCzS7","executionInfo":{"status":"ok","timestamp":1695271360442,"user_tz":240,"elapsed":2519,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"f3ee75be-79b4-4593-c74e-7d5a1d06e48b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  origin dest    N\n","0    SEA  RNO    8\n","1    SEA  DTW   98\n","2    SEA  CLE    2\n","3    SEA  LAX  450\n","4    PDX  SEA  144\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Create pd_temp\n","pd_temp = pd.DataFrame(np.random.random(10))\n","\n","# Create spark_temp from pd_temp\n","spark_temp = spark.createDataFrame(pd_temp)\n","\n","# Examine the tables in the catalog\n","print(spark.catalog.listTables())\n","\n","# Add spark_temp to the catalog\n","spark_temp.createOrReplaceTempView(\"temp\")\n","\n","# # Examine the tables in the catalog again\n","print(\"temp\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"he_-90htDG-l","executionInfo":{"status":"ok","timestamp":1695271442046,"user_tz":240,"elapsed":1419,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"b2c553ed-d4ff-4ea7-c12d-f404a1a5d051"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Table(name='flights_temp_table', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n","temp\n"]}]},{"cell_type":"markdown","source":["# People Data Analysis"],"metadata":{"id":"tiePVebnKiI6"}},{"cell_type":"markdown","source":["Spark DataFrames are the workhouse and main way of working with Spark and Python post Spark 2.0. DataFrames act as powerful versions of tables, with rows and columns, easily handling large datasets. The shift to DataFrames provides many advantages:\n","\n","- A much simpler syntax\n","- Ability to use SQL directly in the dataframe\n","- Operations are automatically distributed across RDDs\n","\n","If you've used R or even the pandas library with Python you are probably already familiar with the concept of DataFrames. Spark DataFrame expand on a lot of these concepts, allowing you to transfer that knowledge easily by understanding the simple syntax of Spark DataFrames. Remember that the main advantage to using Spark DataFrames vs those other programs is that Spark can handle data across many RDDs, huge data sets that would never fit on a single computer."],"metadata":{"id":"FNS58Zo9EcZi"}},{"cell_type":"code","source":["# creating a dataframe\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"],"metadata":{"id":"Od5jlzYjKm3-","executionInfo":{"status":"ok","timestamp":1695418386470,"user_tz":240,"elapsed":138,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Load json file in people dataframe\n","\n","people = spark.read.json('/content/people.json')\n","\n","people.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oa1kApZpFu6-","executionInfo":{"status":"ok","timestamp":1695418388933,"user_tz":240,"elapsed":830,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"d35ae915-9ef7-4e4b-87b9-4db0ae3ef4d6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+\n","| age|   name|\n","+----+-------+\n","|null|Michael|\n","|  30|   Andy|\n","|  19| Justin|\n","+----+-------+\n","\n"]}]},{"cell_type":"code","source":["# print schema of people df\n","\n","people.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LNM2ASUGRp6","executionInfo":{"status":"ok","timestamp":1695418390765,"user_tz":240,"elapsed":131,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"79fe90f8-73a4-42bf-bc12-f52fe1b0be10"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- age: long (nullable = true)\n"," |-- name: string (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["# Find the column names of df\n","\n","people.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFW6m0U2Gd7X","executionInfo":{"status":"ok","timestamp":1695418395602,"user_tz":240,"elapsed":113,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"715a4030-5315-4771-fab7-cbf9fdaa92b0"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['age', 'name']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Find datatype of the columns\n","\n","people.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRFep56mGl3q","executionInfo":{"status":"ok","timestamp":1695418397587,"user_tz":240,"elapsed":265,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"b922b967-749a-4b35-f06e-fafc9aa5b9e6"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[summary: string, age: string, name: string]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Infer Schema in df\n","\n","people.describe().show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkDg_xPSGuQY","executionInfo":{"status":"ok","timestamp":1695418405281,"user_tz":240,"elapsed":2832,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"ee2edac7-a57b-45ba-ad05-cdbe7d419743"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------------------+-------+\n","|summary|               age|   name|\n","+-------+------------------+-------+\n","|  count|                 2|      3|\n","|   mean|              24.5|   null|\n","| stddev|7.7781745930520225|   null|\n","|    min|                19|   Andy|\n","|    max|                30|Michael|\n","+-------+------------------+-------+\n","\n"]}]},{"cell_type":"markdown","source":["Some datatypes make it easier to infer schema (like tabular formats such as csv).\n","\n","However you often have to set the schema yourself if you aren't dealing with a .read method that doesn't have inferSchema() built-in.\n","\n","Spark has all the tools you need for this, it just requires a very specific structure:"],"metadata":{"id":"BdB2w92NHPRD"}},{"cell_type":"code","source":["from pyspark.sql.types import StructField, StringType, IntegerType, StructType"],"metadata":{"id":"iveN659hIRO-","executionInfo":{"status":"ok","timestamp":1695418411469,"user_tz":240,"elapsed":117,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["we need to create the list of Structure fields\n","\n","* :param name: string, name of the field.\n","* :param dataType: :class:`DataType` of the field.\n","* :param nullable: boolean, whether the field can be null (None) or not."],"metadata":{"id":"mDL3TeZqIgUR"}},{"cell_type":"code","source":["# Define schema for the file\n","\n","data_schema = [StructField('age', IntegerType(), True), StructField('name', StringType(), False)]\n","\n","final_struct = StructType(fields = data_schema)\n","\n","people1 = spark.read.json('/content/people.json', schema = final_struct)\n","\n","people1.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8LyasT1If4C","executionInfo":{"status":"ok","timestamp":1695323433263,"user_tz":240,"elapsed":138,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"f6723ec2-3edf-4ff4-fb2f-89a03e6bdd64"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- age: integer (nullable = true)\n"," |-- name: string (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["# Understanding the data\n","\n","people['age']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zN4QiSILMzi","executionInfo":{"status":"ok","timestamp":1695418472274,"user_tz":240,"elapsed":125,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"1c39cf1c-c237-4ef1-9453-811ddf8a7f7d"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Column<'age'>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["type(people['age'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gf6obM4ILhMB","executionInfo":{"status":"ok","timestamp":1695323922413,"user_tz":240,"elapsed":231,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"6a0d7793-5f12-40f3-fda7-3788dbdca236"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyspark.sql.column.Column"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["people.select('age')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoKIlRMlLi4r","executionInfo":{"status":"ok","timestamp":1695323943638,"user_tz":240,"elapsed":145,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"c3ef3b24-ba54-40cc-897d-d0b28ca5623d"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[age: int]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["type(people.select('age'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPniRqnrLqbM","executionInfo":{"status":"ok","timestamp":1695323966943,"user_tz":240,"elapsed":135,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"fd5942bf-3072-4b31-820d-b887622e281f"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyspark.sql.dataframe.DataFrame"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["people.select('age').show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5u2ziirLwUR","executionInfo":{"status":"ok","timestamp":1695323993557,"user_tz":240,"elapsed":463,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"9bfeb969-29ab-4a34-a1cb-552ca6b00724"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+\n","| age|\n","+----+\n","|null|\n","|  30|\n","|  19|\n","+----+\n","\n"]}]},{"cell_type":"code","source":["# returns 2 records\n","\n","people.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkDXN7MLL3Tn","executionInfo":{"status":"ok","timestamp":1695324074829,"user_tz":240,"elapsed":285,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"bbce185b-80ad-455f-ec68-6e765dc37237"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(age=None, name='Michael'), Row(age=30, name='Andy')]"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["people.select(['name', 'age']).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-9xLcXXPOmT","executionInfo":{"status":"ok","timestamp":1695324999973,"user_tz":240,"elapsed":397,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"bad39382-7d4a-4015-c5e5-4be7fcd2258f"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+----+\n","|   name| age|\n","+-------+----+\n","|Michael|null|\n","|   Andy|  30|\n","| Justin|  19|\n","+-------+----+\n","\n"]}]},{"cell_type":"code","source":["# Adding new columns by copying\n","\n","people.withColumn('newage', people['age']).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73kLe2X2POdH","executionInfo":{"status":"ok","timestamp":1695325095305,"user_tz":240,"elapsed":359,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"9d1ed932-041d-4a40-ddd1-9372eed9fa9d"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+------+\n","| age|   name|newage|\n","+----+-------+------+\n","|null|Michael|  null|\n","|  30|   Andy|    30|\n","|  19| Justin|    19|\n","+----+-------+------+\n","\n"]}]},{"cell_type":"code","source":["people.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yElTBjOLQFZT","executionInfo":{"status":"ok","timestamp":1695325120610,"user_tz":240,"elapsed":171,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"2bf65744-1d66-4a6d-df94-13cf5967494b"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+\n","| age|   name|\n","+----+-------+\n","|null|Michael|\n","|  30|   Andy|\n","|  19| Justin|\n","+----+-------+\n","\n"]}]},{"cell_type":"code","source":["# Rename column\n","\n","people.withColumnRenamed('age','superage').show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D82XogmKQKP6","executionInfo":{"status":"ok","timestamp":1695325230015,"user_tz":240,"elapsed":302,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"6002ad94-3f8b-430c-a3df-3b36498d6478"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+-------+\n","|superage|   name|\n","+--------+-------+\n","|    null|Michael|\n","|      30|   Andy|\n","|      19| Justin|\n","+--------+-------+\n","\n"]}]},{"cell_type":"code","source":["# Create new column with double the age\n","\n","people.withColumn('Double age', people['age']*2).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sWJz_hsmRdwx","executionInfo":{"status":"ok","timestamp":1695325543360,"user_tz":240,"elapsed":425,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"aad5d637-6251-4f22-ddb9-8db9c8ab43f3"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+----------+\n","| age|   name|Double age|\n","+----+-------+----------+\n","|null|Michael|      null|\n","|  30|   Andy|        60|\n","|  19| Justin|        38|\n","+----+-------+----------+\n","\n"]}]},{"cell_type":"code","source":["# Create new column by adding 5 years to age column\n","\n","people.withColumn('After 5', people['age']+5).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MFIDOo_IRuu8","executionInfo":{"status":"ok","timestamp":1695325592349,"user_tz":240,"elapsed":283,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"6d42863f-cfc4-4837-bde2-d518cd40cbbf"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+-------+\n","| age|   name|After 5|\n","+----+-------+-------+\n","|null|Michael|   null|\n","|  30|   Andy|     35|\n","|  19| Justin|     24|\n","+----+-------+-------+\n","\n"]}]},{"cell_type":"code","source":["# Create new column by halfing the age\n","import pyspark.sql.functions as F\n","\n","people.withColumn('Half age', F.round(people['age']/2)).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSoA39L9SAOd","executionInfo":{"status":"ok","timestamp":1695325816120,"user_tz":240,"elapsed":224,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"24a8ca2b-be23-4b66-b166-55540d2c05c5"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+--------+\n","| age|   name|Half age|\n","+----+-------+--------+\n","|null|Michael|    null|\n","|  30|   Andy|    15.0|\n","|  19| Justin|    10.0|\n","+----+-------+--------+\n","\n"]}]},{"cell_type":"code","source":["# Using SQL\n","\n","# Register the Datframe as a SQL temporary view\n","\n","people.createOrReplaceTempView('people_sql')\n","\n","results_sql = spark.sql('SELECT * FROM people_sql')\n","\n","results_sql.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnJpwN5fS39j","executionInfo":{"status":"ok","timestamp":1695326064375,"user_tz":240,"elapsed":293,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"4debb30d-f637-4bfa-8ac1-fa330bc0d4be"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+\n","| age|   name|\n","+----+-------+\n","|null|Michael|\n","|  30|   Andy|\n","|  19| Justin|\n","+----+-------+\n","\n"]}]},{"cell_type":"code","source":["# filter all people whose age is >30 years\n","\n","results_age = spark.sql('SELECT * FROM people_sql WHERE age>=30')\n","\n","results_age.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EukTVgxTTtqQ","executionInfo":{"status":"ok","timestamp":1695329552707,"user_tz":240,"elapsed":295,"user":{"displayName":"Aparna M","userId":"10414841739150047961"}},"outputId":"6a771a2d-e084-4f80-8a4c-c9211aea7a6a"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+----+\n","|age|name|\n","+---+----+\n","| 30|Andy|\n","+---+----+\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6KM-hNdrUDbg"},"execution_count":null,"outputs":[]}]}